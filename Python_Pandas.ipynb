{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "\n",
    "Author: Yujiang Peng\n",
    "\n",
    "Date: Dec 20, 2019\n",
    "\n",
    "1. 数据结构\n",
    "2. 缺失值\n",
    "3. 基本函数\n",
    "4. 数据聚合与群运算\n",
    "5. Data Wrangling: 合并、重塑、清洗、转化\n",
    "6. 获取数据\n",
    "7. 描述性统计方法\n",
    "8. 时间序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 数据结构\n",
    "- s1、s2为序列series实例名称\n",
    "- dict1为字典实例名称\n",
    "## 1.1 series (一维)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Series([1,2], index = ['a','b']) #创建序列\n",
    "s1 = pd.Series(dict1) #可将序列视为固定长度的字典；可替代字典\n",
    "s1.values #获取序列值\n",
    "s1['a'] #通过索引获取序列值\n",
    "    s1[['b','a']] #通过索引获取序列值\n",
    "s1.index #获取序列的索引\n",
    "s1.name #获取名称属性；默认值为空None\n",
    "    s1.index.name\n",
    "s1 + s2 #具有相同索引的元素相加\n",
    "s1.unique() #返回唯一值，但未排序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 dataframe (二维)\n",
    "- dataframe(DF)数据结构可视为序列的字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建DF（由长度相同的列表或者Numpy数组创建）\n",
    "dict1 = {'state':['Ohio','CA'], 'year':[2000,2001]}\n",
    "df1 = pd.DataFrame(dict1) #列按顺序放置\n",
    "df1 = pd.DataFrame(dict1, index=['row1','row2']) #设置(行)索引值\n",
    "df1 = pd.DataFrame(dict1, columns=['year','state']) #列按给定顺序放置\n",
    "# 创建DF（由嵌套字典创建，内部键值为行索引值）\n",
    "dict1 = {'col1':  {'row1': 1, 'row2': 2}, 'col2': {'row1': 3, 'row2': 4} }\n",
    "df1 = pd.DataFrame(dict1)\n",
    "\n",
    "df1.columns # 获取列、行名\n",
    "df1.index\n",
    "\n",
    "df1.columns.name #获取名称属性（默认值为空None）\n",
    "df1.index.name\n",
    "\n",
    "df1.values #获取值；返回数据为二维数组形式\n",
    "\n",
    "df1.['state'] #将列获取为序列\n",
    "df1.state\n",
    "\n",
    "df1.ix['row2'] #将行获取为序列\n",
    "df1.ix[1]\n",
    "\n",
    "df1['eastern'] = df1.state == 'Ohio' #创建新列\n",
    "\n",
    "df1['eastern'] #删除列\n",
    "\n",
    "df1.T #交换行和列；转置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 panel date (三维)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建panel date（每一项均为DF）\n",
    "import pandas_datareader.data as web\n",
    "panel1 = pd.Panel({stk : web.get_data_yahoo(stk, '1/1/2000', '1/1/2010')    \n",
    "for stk in ['AAPL', 'IBM']}) #数据维数2 (item) * 861 (major) * 6 (minor)\n",
    "\n",
    "# 堆叠Df表\n",
    "panel1 = panel1.swapaxes('item', 'minor')\n",
    "panel1.ix[:, '6/1/2003', :].to_frame() #DF有to_panel()方法；与to_frame()相反\n",
    "=> Stacked DF (with hierarchical indexing **) :\n",
    "#  Open High Low Close Volume Adj-Close\n",
    "#  major         minor\n",
    "#  2003-06-01    AAPL\n",
    "#                IBM\n",
    "#  2003-06-02    AAPL\n",
    "#                IBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 索引对象\n",
    "即保存有axis label和其它元数据的不可变对象（如轴名）：\n",
    "- 如Index, MultiIndex, DatetimeIndex, PeriodIndex\n",
    "- 在创建序列或DF时从内部转换为索引的标签\n",
    "- 可作为固定大小的集合，且类似于数组"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 分层索引\n",
    "- 一个轴上的多层索引：用低维的形式处理高维数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多索引\n",
    "series1 = Series(np.random.randn(6), index = [['a', 'a', 'a', 'b', 'b',\\\n",
    "         'b'], [1, 2, 3, 1, 2, 3]])\n",
    "series1.index.names = ['key1', 'key2']\n",
    "\n",
    "# 序列部分索引\n",
    "series1['b']  # Outer Level\n",
    "series1[:, 2] # Inner Level\n",
    "\n",
    "# DF部分索引\n",
    "df1['outerCol3','InnerCol2']               \n",
    "    #or            \n",
    "df1['outerCol3']['InnerCol2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 交换和排序层级"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交换层级（行的顺序不变，只交换两层）\n",
    "swapSeries1 = series1.\n",
    "swaplevel('key1', 'key2')\n",
    "\n",
    "# 排序层级\n",
    "series1.sortlevel(1) #根据内部第一层排序\n",
    "\n",
    "# 交换和排序\n",
    "# 最外层索引经排序后数据选择性能更好；调用sortlevel(0) or sort_index()\n",
    "series1.swaplevel(0, 1).sortlevel(0) #行的顺序变化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 按层级汇总统计信息\n",
    "    - 序列和DF的多数函数均有level选项，可指定axis的层级"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.sum(level = 'key2') #具有相同层级key2的行求和\n",
    "df1.sum(level = 'col3', axis=1) #列求和\n",
    "#实际上利用了groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 将dataframe的列作为索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新的采用列作为索引的DF\n",
    "df2 = df1.set_index(['col3', 'col4']) #col3成为最外层索引；col4成为内层索引\n",
    "    #col3, col4的值成为索引值；默认将会从DF数据中移除，可设置drop=False不移除\n",
    "# reset_index与set_index相反，可见多层索引移变成列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python\n",
    "NaN - np.nan(not a number)\n",
    "#Pandas\n",
    "NaN或python内置的None表示缺失值\n",
    "#采用pd.isnull(),  pd.notnull()或series1/df1.isnull()来检测缺失数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 筛选出缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropna()仅返回非空数据，不修改源数据\n",
    "df1.dropna() #去掉所有含缺失值的行\n",
    "df1.dropna(axis=1) #去掉所有含缺失值的列\n",
    "df1.dropna(how = 'all') #去掉数据全部缺失的行\n",
    "df1.dropna(thresh = 3) #去掉数据数量少于3的行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 填充缺失数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.fillna(0) #将所有缺失值填充为0\n",
    "df1.fillna('inplace = True') #在数据内修改\n",
    "df1.fillna({'col1' : 0, 'col2' : -1}) #为每一列采用不同的填充方法\n",
    "df1.fillna(method = 'ffill', limit = 2) #仅填充前两个缺失值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 基本函数\n",
    "## 3.1 索引（切片/分割子集）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 终点包含在pandas标签切片中，如series1['a':'c']；而python切片则不包含\n",
    "# 2. 注意pandas非标签（如整数）切片也不包含\n",
    "#列索引\n",
    "df1['col1']\n",
    "df1[ ['col1', 'col3'] ]\n",
    "#行索引\n",
    "df1.ix['row1']\n",
    "df1.ix[ ['row1', 'row3'] ]\n",
    "#同时由列和行索引\n",
    "df1.ix[['row2', 'row1'], 'col3']\n",
    "#布尔值索引\n",
    "df1[ [True, False] ]\n",
    "df1[df1['col2'] > 6] #返回col2值大于6的df\n",
    "    # df1['col2'] > 6返回一个布尔值序列，决定各值是否出现在结果中。\n",
    "    # 避免使用整数索引，它可能对引起故障（如series1[-1]）；如果一定要使用基于位置\n",
    "    # 的索引；那么序列使用iget_value()，DF则使用irow/icol()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 删除行/列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除操作返回一个新的对象（如DF)\n",
    "#删除行（默认值为aixs=0）\n",
    "df1.drop('row1')\n",
    "df1.drop(['row1', 'row2'])\n",
    "#删除列\n",
    "df1.drop('col2', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 重新索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#修改索引值\n",
    "date_index = pd.date_range('01/23/2010', periods = 10, freq = 'D')\n",
    "#重新索引，默认是修改行索引\n",
    "df1.reindex(date_index)\n",
    "#用0代替缺失索引值\n",
    "df1.reindex(date_index, fill_value = 0) \n",
    "#重新索引列\n",
    "df1.reindex(columns = ['a', 'b'])\n",
    "#重新索引行和列\n",
    "df1.reindex(index = [..], columns = [..])\n",
    "#简洁索引\n",
    "df1.ix[[..], [..]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 算术运算与数据对齐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#执行运算 df1 + df2 时，对于不重叠的部分索引，进行内部数据对齐后索引值会变成NaN\n",
    "# 1. 使用0来代替不重叠的部分索引，而不是NaN\n",
    "df1.add(df2, fill_value = 0)\n",
    "# 2. 实用操作\n",
    "df1 - df1.ix[0] #每一行均减去df1的第一行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 排序(sorting)与排名(ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 索引/列排序 sort index/column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. sort_index()函数返回一个新的、排序后的对象。默认升序 ascending = True\n",
    "# 2. 默认行排序，将参数 axis=1 可进行列排序\n",
    "## 索引/列排序意味着排序行/列标签，而不是排序数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 数据排序 sort data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 缺失值 np.nan 默认排在序列 Series 的末尾\n",
    "#序列排序\n",
    "sortedS1 = series1.order()\n",
    "series1.sort() # In-place sort  \n",
    "#DF排序\n",
    " df1.sort_index(by = ['col2', 'col1'])  #先col2，再col1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 排名 ramking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#多个排名相同则采用其排名的平均值\n",
    "series1.rank() #返回各元素排名\n",
    "df1.rank(axis = 1) #排名各行的值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 函数应用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Numpy可以很好地处理pandas对象：np.abs(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用函数处理各列或者各行（默认处理各行，axis=0）\n",
    "f = lambda x: x.max() - x.min() # 返回一个标量值\n",
    "#\n",
    "# 下面两个函数均返回多个值\n",
    "def f(x): return  # 对 x 应用函数 f\n",
    "Series([x.max(), x.min()]) # 返回最大最小值\n",
    "#\n",
    "df1.apply(f)\n",
    "\n",
    "# 用函数处理各个元素\n",
    "f = lambda x: '%.2f' %x # 均保留两位小数\n",
    "df1.applymap(f)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 唯一性、个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series1/df1.index.is_unique # 可检查唯一性\n",
    "pd.value_counts() # 数值数量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 数据聚合与群组运算\n",
    "- 分类数据集且应用函数到各组，不管是聚集还是转换\n",
    "- 注意：时间序列（Time Series）数据参见时间序列部分；resampling为groupby的特殊用例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 groupby "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算组的平均值\n",
    "df1.groupby('col2').mean()\n",
    "# groupby多个键\n",
    "df1.groupby([df1['col2'], df1['col3']]).mean()\n",
    "# groupby对象：仅计算内部数据关于组键df1['col2']\n",
    "grouped = df1['col1'].groupby(df1['col2'])\n",
    "grouped.mean() # gets the mean of each group formed by 'col2'\n",
    "\n",
    "# 索引groupby对象\n",
    "# 选取col1来聚集\n",
    "df1.groupby('col2')['col1'] \n",
    "    # or\n",
    "df1['col1'].groupby(df1['col2'])\n",
    "# 注意：缺失值均从结果中排除。\n",
    "\n",
    "# 1. 通过groupby对象迭代\n",
    "# 生成元组序列，元组每个元素含有两个数据（组名和数据）\n",
    "# 组名为单值；数据为通过组名筛选后的DF\n",
    "for name, groupdata in df1.groupby('col2'): \n",
    "# 如果groupby多个键，那么元组第一个元素为元组的键值\n",
    "for (k1, k2), groupdata in df1.groupby(['col2', 'col3']):\n",
    "#\n",
    "# 将组转换为字典\n",
    "dict(list(df1.groupby('col2'))) # col2的值将成为字典的键\n",
    "# 通过dtype来group列\n",
    "grouped = df1.groupby([df1.dtypes, axis = 1)\n",
    "dict(list(grouped))\n",
    "\n",
    "# 2. 通过函数分组\n",
    "# 每个被传递作为群组键的函数都会被每个值（默认为行索引）调用一次。\n",
    "# 且返回值被作为组名（假设含索引已被命名）。\n",
    "df1.groupby(len).sum() # 返回一个行索引为名字长度的DF；因此，具有相同名字长度的名字将被求和。列名不变。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 数据聚合\n",
    "- 表示从数组产生标量值的数据转换，如平均值、最大值等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义函数\n",
    "def func1(array): ...\n",
    "grouped.agg(func1)\n",
    "# 使用列名作为函数名来获取DF\n",
    "grouped.agg([mean, std])\n",
    "# 使用自定义的列名来获取DF\n",
    "grouped.agg([('col1', mean), ('col2', std)])\n",
    "# 对不同列采用不用函数\n",
    "grouped.agg({'col1' : [min, max], 'col3' : sum})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 群组操作与转换\n",
    "- **Agg()**是数据转换的特例，**one-dimensional array to scalar**的简称\n",
    "- **Transform()**是一种特殊的数据转换：\n",
    "    - 它将一个函数应用到每个组，如果产生的是标量值，这个值将被置于该组的**每行**\n",
    "    - 被传递的函数要么产生一个标量值，要么产生一个具有相同大小的转换后的数组\n",
    "- 通用目的转换**apply()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you_func仅需返回一个pandas对象或者一个标量\n",
    "df1.groupby('col2').apply(your_func1)\n",
    "\n",
    "# 例一：年度与SPX的相关性\n",
    "# “close_price” is DF with stocks and SPX closed price columns and dates index \n",
    "returns = close_price.pct_change().dropna()\n",
    "by_year = returns.groupby(lambda x : x.year) \n",
    "spx_corr = lambda x : x.corrwith(x['SPX'])\n",
    "by_year.apply(spx_corr)\n",
    "\n",
    "# 例二：探索回归\n",
    "import statsmodels.api as sm\n",
    "def regress(data, y, x):\n",
    "   Y = data[y]; X = data[x]\n",
    "   X['intercept'] = 1\n",
    "   result = sm.OLS(Y, X).fit()\n",
    "   return result.params    \n",
    "by_year.apply(regress, 'AAPL', ['SPX'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Data Wrangling: 合并、重塑、清洗、转化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 组合与合并数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. pd.merge() aka database 'join' # 在DF中通过一个或多个键连接行\n",
    "##列合并（常用）\n",
    "df3 = pd.merge(df1, df2, on = 'col2')\n",
    "        # 使用所有重叠的列名作为键来合并。好的做法是列出这些键。on = ['col2', 'col3']\n",
    "        # 如果df1和df2中键名不同，可使用选项：left on = 'lkey', right on = 'rkey'\n",
    "    # INNER为默认值，也可有其他选择: how = 'outer/ left/ right'\n",
    "    # 在df3中df1和df2的索引被丢弃\n",
    "##行合并\n",
    "df3 = pd.merge(df1, df2, left_index = True, right_index = True)\n",
    "    # 将索引作为合并键：具有相同索引值的aka行被合并。\n",
    "\n",
    "\n",
    "2. pd.concat() # 沿某个轴堆叠（默认沿着行：axis = 0）\n",
    "df3 = pd.concat([df1, df2], ignore_index = True) # 丢弃df3中索引\n",
    "    # 如果df1有2行，df2有3行，那么合并后df3有5行。\n",
    "\n",
    "\n",
    "3. combine_first() # 合并具有重叠的数据，补充缺失值。\n",
    "df3 = df1。combine_first(df2)\n",
    "    # df1和df2的索引全部或部分重叠。\n",
    "    # 如果某行存在于df1而不存在与df2中，这行将出现在df3中。\n",
    "    # 如果df1和df2中分别有一行具有相同的索引值，但是df1中行的某列值为空，则在df3中改行将从df2中行获得数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 重塑和旋转数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. 重塑具有多层索引的数据\n",
    "series1 = df1.stack()\n",
    "    # 旋转（最内层*）列至行作为最内层的索引，使得series具有多层索引。\n",
    "df1 = series1.unstack()\n",
    "    # 旋转（最内层*）行至列作为最内层列。\n",
    "        # 默认为stack/unstack最内层。如果想要不同的层，如stack(level = 0)则为最外层。\n",
    "# 注意：unstacking可能会导致丢失数据，如果层中值有缺失。stacking会默认过滤掉缺失值，如data.unstack() .stack()\n",
    "\n",
    "\n",
    "2. 旋转数据\n",
    "# 在数据库和CSV中常用的保存多个时间序列的格式为\n",
    "Long/Stacked Format: 'date, stock_name, price'\n",
    "# 然而，一个具有上述三个列数据的DF很难处理。因此，更推荐'wide'格式：'date'作为行索引，'stock_name'作为列，'price'作为DF数据值。\n",
    "pivotedDF2 = df1.pivot('date', 'stock_name', 'price')\n",
    "    # 例如 pivotedDF2：\n",
    "    #             AAPL     IBM     JD\n",
    "    # 2003-06-01  120.2    110.1   20，8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 常用操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. 移除重复行\n",
    "serial1 = df1。duplicated() # 布尔值序列，表示每行是否重复。\n",
    "df2 = df1.drop_duplicates() # 重复的行被移除\n",
    "\n",
    "\n",
    "2. 基于列值添加新列\n",
    "df1['newCol'] = df1['col2'].map(dict1) # 将col2的值映射为dict1的键，得到dict1的值。\n",
    "df1['newCol'] = df1['col2'].map(func1) # 将一个函数应用到col2的每个值。\n",
    "\n",
    "\n",
    "3. 替换值\n",
    "# 替换不是In-Place, \n",
    "df2 = df1.replace(np.nan, 100)\n",
    "# 同时替换多个值\n",
    "df2 = df1.replace([-1, np.nan], 100)\n",
    "df2 = df1.replace([-1, np.nan], [1, 2])\n",
    "# 变量也作为字典\n",
    "df2 = df1.replace({-1: 1, np.nan : 2})\n",
    "\n",
    "\n",
    "4. 重命名轴索引\n",
    "## 将索引转换为大写\n",
    "df1.index = df1.index.map(str.upper)\n",
    "## 将'row1'重命名为'newRow1'\n",
    "df2 = df1.rename(index = {'row1': 'newRow1'}, columns = str.upper) # 可选项，inplace = True\n",
    "\n",
    "\n",
    "5. 离散化和binning\n",
    "## 连续数据通常被离散化为bins来分析\n",
    "    # 将数字(18-26], (26-35]分成两个Bins\n",
    "    bins = [18, 26, 36]\n",
    "    cat = pd.cut(array1, bins, labels=[..]) # cat是类别对象\n",
    "    pd.value_counts(cat)\n",
    "    cat = pd.cut(array1, numofBins) # 基于array1的最小最大值计算等长的bins\n",
    "    cat = pd.qcot(array1, numofBins) # 基于样本数量划分数据，大小大致相同的bins\n",
    "\n",
    "\n",
    "6. 检测和过滤离群值outliers\n",
    "## any()沿着轴检查各元素是否为真。默认沿着列（axis = 0）检测。\n",
    "df1[(np.abs(df1) > 3).any(axis = 1)] # 选择含有值的绝对值大于三的所有行。\n",
    "\n",
    "# 另一个有用的函数：np.sign()  返回1或者-1\n",
    "\n",
    "\n",
    "7. 排列组合与随机取样 permutation and ramdom smapling\n",
    "randomOrder = np.random.permutation(df1.shape[0])\n",
    "df2 = df1.take(randomOrder)\n",
    "\n",
    "\n",
    "8. 计算指示符/虚拟变量 indicator/dummy variables\n",
    "## 如果DF中某列有K个不同的值，得到一个含有K列0和1的指示符DF。1表示存在，0表示不存在。\n",
    "dummyDF = pd.get_dummies(df1['col2'], prefix = 'col-') # 将前缀添加到K列名"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 获取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 文本格式（CSV）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(file/URL/file-like-object, sep = ',', header = None)\n",
    "    # 类型推断：无需表明哪些列为数值型、整型、布尔型，或字符串\n",
    "    # 在pandas中，源数据中的缺失数据通常为空字符串、NA、-1、#IND，或NULL。可通过下列选项指出缺失值：na_values = ['NULL']\n",
    "    # 默认分隔符为逗号comma\n",
    "    # 默认第一行为列头\n",
    "\n",
    "df1 = pd.read_csv(.., names = [..])\n",
    "    # 明确指出列头，也表明第一行为数据\n",
    "\n",
    "df1 = pd.read_csv(.., names = [.., 'date'], index_col = 'date')\n",
    "    # 想要使'date'列成为返回DF的行索引\n",
    "\n",
    "df1.to_csv(filepath/sys.stdout, sep = ',')\n",
    "    # 缺失值在输出中呈现为空字符串。因此，最好添加选项：na_rep = 'NULL'\n",
    "    # 默认写行和列的标签。可通过选项禁用：index = False, header = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 JSON (javascript object notation) 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 在浏览器和其他应用程序间通过HTTP请求传递数据的标准格式之一\n",
    "## 比表格化文本CSV更灵活的数据格式\n",
    "\n",
    "# 将JSON字符串转化为Python表格\n",
    "data = json.load(jsonObj)\n",
    "\n",
    "# 将Python对象转化为JSON\n",
    "asJson = json.dumps(data)\n",
    "\n",
    "# 从JSON创建DF\n",
    "df1 = pd.DataFrame(data['name'], columns = ['filed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 XML和HTML数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HTML:\n",
    "doc = lxml.html.parse(urlopen('http://..')).getroot()\n",
    "tables = doc.findall('.//table')\n",
    "rows = tables[1].findall('.//tr')\n",
    "\n",
    "## XML：\n",
    "lxml.objectify.parse(open(filepath)).getroot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 描述性统计方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 相较于同样方法的ndArray, pandas中的描述性统计方法自底向上排除缺失数据\n",
    "### NA（如NaN）值被排除。可通过选项禁用：skipna = False\n",
    "\n",
    "# 列之和（使用axis = 1来求各行之和）\n",
    "serial1 = df1.sum()\n",
    "\n",
    "# 返回获得的最小/最大值索引标签\n",
    "df1.idxmin()\n",
    "df1.idxmax()\n",
    "\n",
    "# 简要统计（如个数、均值、标准差等）\n",
    "# 在非数值数据中，部分统计量（如个数、唯一性）\n",
    "df1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 相关性及协方差 correlation and covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov(), corr()\n",
    "corrwith() # 成对相关性：aka计算一个DF与一个序列。若输入不是序列，而是另一个DF,则\n",
    "            #将计算相匹配的列名的相关性，如returns.corrwith(volumes)\n",
    "\n",
    "# 实例：相关性\n",
    "import pandas_datareader.data as web\n",
    "data = {}\n",
    "for ticker in ['AAPL', 'JD']:\n",
    "    data[ticker] = web.get_data_yahoo(ticker, '1/1/200', '1/1/2010')\n",
    "    prices  = pd.DataFrame({ticker: d['AdjClose'] for ticker, d in data.iteritems()})\n",
    "    volumes = ...\n",
    "returns = prices.pct_change()\n",
    "returns.AAPL.corr(returns.JD)\n",
    "    # 序列corr()计算两个序列中重叠、non-NA、且通过索引对齐的值的相关性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. 时间序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2011, 1, 20, 0, 0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Python表示日期和时间的标准库数据类型\n",
    "#import datetime time calender\n",
    "    # datetime应用广泛，它同时保存日期和精确到微秒的时间\n",
    "## Pandas表示日期和时间的数据类型\n",
    "#import Timestamp  # 可代替datetime对象\n",
    "\n",
    "\n",
    "# 将字符串转换为DataTime\n",
    "from datetime import datetime\n",
    "datetime.strptime('8/8/2008', '%m/%d/%Y')\n",
    "\n",
    "# 获取当前时间\n",
    "now = datetime.now()\n",
    "\n",
    "# DataTime计算\n",
    "from datetime import timedelta\n",
    "datetime(2011, 1, 8) + timedelta(12) => 2011-01-20\n",
    "    # timedelta表示两个datetime对象的时间差\n",
    "\n",
    "# 将字符串转化为Pandas Timest类型\n",
    "timestamps = pd.to_datetime(['8/8/2008', ..])\n",
    "    # NaT (Not a Time)在Pandas中表示Timestamp数据的NA值\n",
    "pd.to_datetime('') => NaT\n",
    "pd.isnull(NaT) => True # 缺失值，如：空字符串"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Panda时间序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建时间序列\n",
    "ts1 = pd.Series(np.random.randn(2), index = [ datetime(2011, 1, 2), ... ])\n",
    "ts1 = pd.Series(..., index = pd.date_range('1/1/2000', periods = 1000))\n",
    "    # 每隔一天，一共1000天\n",
    "    # ts1.index为DatetimeIndex Panda类\n",
    "    # 索引值ts1.index[0]是Panda Timestamp对象，其使用NumPy的datetime64类型储存纳秒精度的时间戳\n",
    "    # 时间戳类保存有频率信息和时区\n",
    "    # ts1.index.dtype => datetime64[ns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 索引（切片/子集）\n",
    "    变量可为一个string date、datetime、或Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选取2001年\n",
    "ts1['2001']\n",
    "df1.ix['2001']\n",
    "\n",
    "# 选取2001 6月\n",
    "ts1['2001-06']\n",
    "\n",
    "# 选取时间段\n",
    "ts1['1/1/2001':'8/1/2001']\n",
    "\n",
    "# 选取从某天开始的时间\n",
    "ts1[datetime(2001, 1, 8):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 常用操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取某天之前的时间序列\n",
    "ts1.truncate(after = '1/8/2011')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 日期范围、频率、shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas里的通用时间序列无规律，aka没有固定的频率。\n",
    "# 但是通常需要固定的频率，如每日、每月等\n",
    "\n",
    "# Resampling部分\n",
    "## 转换为固定的每日频率\n",
    "## 如需要，引入缺失值NaN\n",
    "ts1.resample('D', how = ...)\n",
    "\n",
    "\n",
    "1. 频率及日期偏移\n",
    "# Pandas中频率由基础频率和乘法器组成。基础频率通常指一个字符串别名，如'M', 'H'\n",
    "freq = '4H'\n",
    "freq = '1h30min'\n",
    "    # 标准美国标准股每月满期为每月第三个周五：freq = 'WOM-3FRI'\n",
    "\n",
    "2. 生成日期范围\n",
    "# 默认频率是每日\n",
    "pd.date_range(begin, end)\n",
    "pd.date_range(begin or end, periods=n)\n",
    "    # 选项freq = 'BM'表示每月最后一个工作日\n",
    "\n",
    "3. 日期移位\n",
    "## 移位表示将数据沿着时间前移或后移\n",
    "## 序列和DF的 shift() 进行简单移位，aka索引不移位，只移值。\n",
    "\n",
    "# ts1为每日数据\n",
    "ts1.shift(1) # 将昨天的值移到今天，今天的移到明天，等\n",
    "\n",
    "# ts1为任意时间序列数据。数据移位3天。\n",
    "ts1.shift(3, freq = 'D')\n",
    "ts1.shift(1, freq = '3D')\n",
    "\n",
    "# 常用移位操作：计算%变化\n",
    "ts1 / ts.shift(1) -1\n",
    "\n",
    "    # shift()的返回值中，部分数据值可能为NaN\n",
    "\n",
    "## 其他移位方法\n",
    "from pandas.tseries.offsets import Day, MonthEnd\n",
    "datetime(2008, 8, 8) + 3*Day() => 2008-08-11\n",
    "datetime(2008, 8, 8) + MonthEnd(2) => 2008-09-30\n",
    "MonthEnd().rollforward(datetime(2008, 8, 8)) => 2008-08-31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 时区操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Daylight saving time (DST)复杂\n",
    "## UTC为当前国际通用标准。时区表示为从UTC的偏移\n",
    "\n",
    "1. Python时区（从第三方库pytz）\n",
    "# 获取时区名\n",
    "pytz.common_timezones\n",
    "# 获取时区对象\n",
    "pytz.timezone('US/Eastern')\n",
    "\n",
    "2. 本地化与转换\n",
    "# 默认的时间序列是简单时区\n",
    "ts1.index.tx => NotImplemented\n",
    "# 创建时间序列时表明时区\n",
    "pd.date_range(tz = 'UTC')\n",
    "# 从简单时区本地化\n",
    "ts1_utc = ts1.tz_localize('UTC')\n",
    "# 更换时区\n",
    "ts1_eastern = ts1_utc.tz_convert('US/Eastern')\n",
    "\n",
    "3. 时区感知时间戳对象\n",
    "    # 若需合并两个不同时区的时间序列，如ts1+ts2，时间戳将自动对齐，结果为UTC。\n",
    "stamp_utc = pd.Timestamp('2008-08-08 03:00', tz = 'UTC')\n",
    "stamp_eastern = stamp_utc.tz_convert(...)\n",
    "\n",
    "# Pandas时间计算  daylight savings time\n",
    "stamp = pd.Timestamp('2012-11-04 00:30', tz = 'US/Eastern') => 2012-11-04-00:30:00 -400 EDT\n",
    "stamp + 2 * Hour() => 2012-11-04-01:30:00 -400 EST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4 重采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 将时间序列从一个频率转换到另一个频率的过程\n",
    "1. 降采样  吸收高频数据为低频数据\n",
    "    ts1.resample('M', how = 'mean') => index: 2000-01-31, 2000-02-29, ...\n",
    "\n",
    "    ts1.resample('M', ..., kind = 'period') => index: 2000-01, 2000-02,...\n",
    "        # 'period'-使用时间区间\n",
    "    \n",
    "    # ts1是从1到100的一分钟数据\n",
    "    00:00:00, 00:01:00, ...\n",
    "    ts1.resample('5min', how = 'sum') => 00:00:00 15 (aka: 1+2+3+4+5)\n",
    "                                         00:05:00 40\n",
    "    # 默认左侧包含\n",
    "    # 选项 closed = 'right' 可切换到右侧包含。还可 label = 'right'\n",
    "    00:00:00 1\n",
    "    00:05:00 20 (aka: 2+3+4+5+6)\n",
    "\n",
    "    ts1.resample('5min', how = 'ohlc') # 返回4列的DF: open, high, low, close\n",
    "\n",
    "2. 升采用和插值  通过插值使低频变为高频。默认情况下引入缺失值（NaN）\n",
    "        # 插值仅应用于行\n",
    "    df1.resample('D', fill_method = 'ffill')\n",
    "        # Forward fills values，如，索引为3的缺失值将复制索引为2的值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5 时间序列绘图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例：源数据格式-第一列为日期\n",
    "# 使用第一列作为索引，然后解析索引值作为日期\n",
    "prices = pd.read_csv(.., parse_date = True, index_col = 0)\n",
    "px = prices[['AAPL', 'IBM']]\n",
    "px = px.resample('B', fill_method = 'ffill')\n",
    "px['AAPL'].plot()\n",
    "px['AAPL'].ix['01-2008':'03-2012'].plot()\n",
    "px.ix['2008'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.6 移除窗口函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 像其它统计函数一样，这些函数也自动排除缺失数据\n",
    "pd.rolling_mean(px.AAPL, 200).plot()\n",
    "pd.rolling_std(px.AAPL.pct_change(), 22, min_periods = 20).plot()\n",
    "pd.rolling_corr(px.AAPL.pct_change(), px.IBM.pct_change(), 22).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.7 性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "025c05e35a87914ff8cab305acc9d757ae94238974cd96210f46e0855d33df0f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
